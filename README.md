# ğŸ§  Document AI Assistant - Multimodal RAG System

A production-ready Retrieval-Augmented Generation (RAG) system powered by Google Gemini AI and LangChain. This intelligent document assistant processes multiple file formats (PDF, Excel, PowerPoint, Word, Images, Videos) and provides accurate answers with source attribution using advanced vector search and semantic understanding.

## ğŸŒŸ Key Features

### Document Processing
- **ğŸ“„ 9 File Formats Supported**: PDF, CSV, Excel (.xlsx/.xls), PowerPoint (.pptx/.ppt), Word (.docx/.doc), Text, Images (.jpg/.png), Videos (.mp4/.avi/.mov/.mkv)
- **ğŸ–¼ï¸ Multimodal AI**: Uses Gemini's vision capabilities for image text extraction and video content analysis
- **ğŸ“Š Structured Data**: Intelligent processing of tabular data (CSV/Excel) with row-level chunking
- **ğŸ”„ Auto-Reload**: Re-scan documents on demand with progress tracking

### AI & Search Technology
- **ğŸ¤– Google Gemini 2.5 Flash Lite**: Latest generation model for fast, accurate responses
- **ğŸ¯ Semantic Search**: FAISS vector store with Gemini text-embedding-004 for precise retrieval
- **ğŸ’¡ Smart Chunking**: RecursiveCharacterTextSplitter (500 chars, 100 overlap) respects document structure
- **ğŸ“ˆ Retrieval Quality**: Top-8 similarity search with source attribution and metadata

### User Experience
- **ğŸ’¬ Clean Corporate UI**: Modern white/gray design with high-contrast readability
- **âš™ï¸ Dual Modes**: Toggle between RAG Mode (document-grounded) and Gemini-Only (no context)
- **ğŸ“ Source Tracking**: View retrieved chunks with file names, page numbers, and document types
- **ğŸ¨ Responsive Design**: Wide layout optimized for desktop with sidebar controls
- **ğŸ’¾ Persistent Storage**: Vector index saved to disk for faster subsequent loads

---

## ğŸš€ Quick Start Guide

### Prerequisites
- Python 3.11 or higher
- Google Gemini API key ([Get it here](https://aistudio.google.com))
- Windows PowerShell (or bash for macOS/Linux)

### Installation (5 Minutes)

#### 1. Clone and Navigate
```powershell
cd rag_system
```

#### 2. Create Virtual Environment
```powershell
# Windows PowerShell
python -m venv venv
.\venv\Scripts\Activate.ps1

# macOS/Linux
python -m venv venv
source venv/bin/activate
```

#### 3. Install Dependencies
```powershell
pip install --upgrade pip
pip install -r requirements.txt
```

**Troubleshooting**: If you encounter NumPy build errors:
```powershell
pip install numpy==1.26.4 --prefer-binary
```

#### 4. Set API Key
```powershell
# Windows PowerShell
$env:GEMINI_API_KEY='your-gemini-api-key-here'

# Windows CMD
set GEMINI_API_KEY=your-gemini-api-key-here

# macOS/Linux
export GEMINI_API_KEY="your-gemini-api-key-here"
```

**Alternative**: Create a `.env` file in the project root:
```env
GEMINI_API_KEY=your-gemini-api-key-here
```

#### 5. Add Documents
Place your files in the `data/` folder:
```
rag_system/
â””â”€â”€ data/
    â”œâ”€â”€ document.pdf
    â”œâ”€â”€ spreadsheet.xlsx
    â”œâ”€â”€ presentation.pptx
    â”œâ”€â”€ report.docx
    â”œâ”€â”€ photo.jpg
    â””â”€â”€ video.mp4
```

#### 6. Launch Application
```powershell
streamlit run app.py
```

Or use the helper script:
```powershell
.\run_app.ps1
```

The app will open at `http://localhost:8501`

---

## ğŸ“š Supported File Formats

| Category | Extensions | Processing Method | Features |
|----------|------------|-------------------|----------|
| **Documents** | `.pdf` | PyPDFLoader | Page-level metadata, text extraction |
| **Spreadsheets** | `.csv`, `.xlsx`, `.xls` | Pandas + Custom | Row-level chunking, column summaries |
| **Presentations** | `.pptx`, `.ppt` | UnstructuredPowerPointLoader | Slide content extraction |
| **Word Docs** | `.docx`, `.doc` | Docx2txtLoader | Full text with formatting |
| **Text Files** | `.txt` | TextLoader (UTF-8) | Plain text processing |
| **Images** | `.jpg`, `.jpeg`, `.png` | Gemini Vision API | OCR + visual description |
| **Videos** | `.mp4`, `.avi`, `.mov`, `.mkv` | Gemini Multimodal | Scene analysis, text extraction |

**Total Formats**: 9 types covering most business and personal document needs

---

## ğŸ¯ How to Use

### Basic Workflow
1. **Upload Documents**: Add files to the `data/` folder
2. **Build Index**: App automatically scans folder on startup (or click "Re-Scan")
3. **Select Mode**: Choose between RAG Mode (uses docs) or Gemini-Only mode
4. **Ask Questions**: Type queries in the chat interface
5. **Review Sources**: Expand retrieved chunks to see which documents were used

### Example Queries
```
"What are the main topics covered in these documents?"
"Summarize the financial data from the spreadsheet"
"Find information about project deadlines"
"What does the image show?"
"Describe the content of the video"
"Compare the data in the Excel file with the PDF report"
```

### Operation Modes

**ğŸ“„ RAG Mode (Recommended)**
- Uses your documents as context
- Provides grounded, accurate answers
- Shows source attribution
- Best for: Specific questions about your data

**ğŸ¤– Gemini-Only Mode**
- Answers from general knowledge
- No document context used
- Faster responses
- Best for: General questions, brainstorming

---

## âš™ï¸ Configuration & Customization

### Chunking Parameters
Located in `app.py`, line ~260:
```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,           # Characters per chunk (adjust for context)
    chunk_overlap=100,        # Overlap to preserve context
    separators=["\n\n", "\n", ". ", " ", ""],  # Natural boundaries
    length_function=len
)
```

**Tuning Guide**:
- **Larger chunks** (800-1000): More context, slower retrieval, better for long-form docs
- **Smaller chunks** (200-400): More precise, faster retrieval, better for Q&A

### Retrieval Settings
Located in `app.py`, line ~720:
```python
retriever=vector_store.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 8}    # Number of chunks to retrieve
)
```

**Tuning Guide**:
- **k=3-5**: Faster, more focused answers
- **k=8-12**: More comprehensive, slower responses

### Models Configuration
```python
# Generation Model
model="gemini-2.5-flash-lite"  # Fast, cost-effective
temperature=0.7                 # Creativity (0=deterministic, 1=creative)

# Embedding Model
model="models/text-embedding-004"  # Latest Gemini embeddings
```

### UI Styling
All UI styles are in `ui_styles.py`:
- **Color Scheme**: Modify `CUSTOM_CSS` for branding
- **Layout**: Adjust `PAGE_CONFIG` for page setup
- **Typography**: Change font families in CSS

---

## ğŸ“¦ Project Structure

```
rag_system/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ ui_styles.py                # Separated UI styling and config
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ run_app.ps1                # PowerShell launcher script
â”œâ”€â”€ .gitignore                 # Git ignore patterns
â”œâ”€â”€ README.md                  # This file
â”‚
â”œâ”€â”€ data/                      # ğŸ“ Your documents go here
â”‚   â”œâ”€â”€ pdf.pdf
â”‚   â”œâ”€â”€ excel.xlsx
â”‚   â”œâ”€â”€ image.jpg
â”‚   â””â”€â”€ video.mp4
â”‚
â”œâ”€â”€ .faiss_index/              # ğŸ’¾ Vector store (auto-created)
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ index.pkl
â”‚
â”œâ”€â”€ .cache/                    # ğŸ—‚ï¸ Hugging Face cache (optional)
â”œâ”€â”€ .streamlit/                # âš™ï¸ Streamlit config (optional)
â”‚
â””â”€â”€ scripts/                   # ğŸ› ï¸ Helper scripts
    â”œâ”€â”€ setup_conda.ps1
    â”œâ”€â”€ setup_env.ps1
    â””â”€â”€ setup.ps1
```

---

## ğŸ”§ Technical Architecture

### RAG Pipeline Flow
```
ğŸ“„ Documents â†’ ğŸ”„ Loaders â†’ âœ‚ï¸ Chunking â†’ ğŸ§® Embeddings â†’ ğŸ’¾ FAISS Index
                                                                    â†“
ğŸ¤ User Query â†’ ğŸ§® Query Embedding â†’ ğŸ” Similarity Search â†’ ğŸ“‹ Top-K Chunks
                                                                    â†“
ğŸ¤– LLM (Gemini) â† ğŸ“ Prompt + Context â† ğŸ”— RetrievalQA Chain
                                                                    â†“
ğŸ’¬ Answer + ğŸ“š Source Citations
```

### LangChain Components

#### 1. Document Loaders
- **PyPDFLoader**: Extracts text from PDFs with page metadata
- **TextLoader**: UTF-8 text file processing
- **Docx2txtLoader**: Microsoft Word document parsing
- **UnstructuredPowerPointLoader**: PowerPoint slide extraction
- **Custom Loaders**: Pandas for CSV/Excel, Gemini API for images/videos

#### 2. Text Splitter
- **RecursiveCharacterTextSplitter**: Respects document structure (paragraphs â†’ sentences â†’ words)
- **Metadata Preservation**: Carries source info through pipeline
- **Overlap Strategy**: Prevents context loss at boundaries

#### 3. Vector Store
- **FAISS (Facebook AI Similarity Search)**: High-performance vector indexing
- **Persistent Storage**: Saves to `.faiss_index/` directory
- **Similarity Metrics**: L2 distance for semantic search

#### 4. Embeddings
- **GoogleGenerativeAIEmbeddings**: Gemini text-embedding-004 model
- **Dimensions**: 768-dimensional vectors
- **Quality**: Optimized for semantic similarity

#### 5. Retrieval Chain
- **RetrievalQA**: Orchestrates retrieval + generation
- **Chain Type**: "stuff" (concatenates all retrieved docs)
- **Source Tracking**: Returns documents with metadata

#### 6. LLM
- **ChatGoogleGenerativeAI**: Gemini 2.5 Flash Lite
- **Context Window**: 1M tokens
- **Multimodal**: Supports text and images

### Data Flow Example
```python
# 1. Load document
loader = PyPDFLoader("report.pdf")
docs = loader.load()  # [Document(page_content="...", metadata={...})]

# 2. Split into chunks
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
chunks = splitter.split_documents(docs)  # [Doc1, Doc2, ..., DocN]

# 3. Create embeddings
embeddings = GoogleGenerativeAIEmbeddings(model="text-embedding-004")
vector_store = FAISS.from_documents(chunks, embeddings)

# 4. Query
retriever = vector_store.as_retriever(search_kwargs={"k": 8})
qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)
result = qa_chain.invoke({"query": "What is this about?"})

# 5. Get answer + sources
answer = result["result"]
sources = result["source_documents"]
```

---

## ğŸ› ï¸ Troubleshooting

### Common Issues

#### âŒ "GEMINI_API_KEY not found"
**Solution**:
```powershell
# Verify key is set
echo $env:GEMINI_API_KEY  # PowerShell
echo $GEMINI_API_KEY      # Bash

# Set if empty
$env:GEMINI_API_KEY='your-key'  # PowerShell
```

#### âŒ "ModuleNotFoundError: No module named 'X'"
**Solution**:
```powershell
# Reinstall dependencies
pip install --upgrade -r requirements.txt

# If specific module fails
pip install --force-reinstall <module-name>
```

#### âŒ NumPy/FAISS Build Errors
**Solution**:
```powershell
# Use precompiled binaries
pip install numpy==1.26.4 --prefer-binary
pip install faiss-cpu --prefer-binary

# Or use Conda
conda install -c conda-forge faiss-cpu
```

#### âŒ "No documents loaded"
**Checklist**:
1. âœ… Files exist in `data/` folder
2. âœ… File extensions are supported (see table above)
3. âœ… Files are not corrupted or password-protected
4. âœ… Check sidebar build log for specific errors
5. âœ… Verify file permissions (readable)

#### âŒ "API Error: 429 Rate Limit"
**Solution**:
- Wait a few minutes before retrying
- Reduce retrieval count (`k` parameter)
- Check API quota at [Google AI Studio](https://aistudio.google.com)

#### âŒ Slow First Run
**This is normal!** The app is:
1. Loading all documents
2. Creating embeddings (API calls to Gemini)
3. Building FAISS index
4. Saving to disk

**Subsequent runs** load from disk and are much faster.

#### âŒ Empty Responses / "I don't know"
**Solutions**:
- Rephrase your question to be more specific
- Check that relevant documents were loaded (sidebar status)
- Increase retrieval count (`k` parameter)
- Verify document content is relevant to query
- Try RAG Mode if in Gemini-Only mode

### Performance Optimization

#### Speed Up Loading
```python
# Reduce chunk size (faster embedding)
chunk_size = 300

# Reduce retrieval count
search_kwargs={"k": 4}
```

#### Improve Answer Quality
```python
# Increase chunk size (more context)
chunk_size = 800

# Increase retrieval count
search_kwargs={"k": 12}

# Adjust temperature (more deterministic)
temperature=0.3
```

#### Reduce Memory Usage
```python
# Smaller chunks
chunk_size = 250

# Clear cache periodically
st.cache_resource.clear()
```

---

## ğŸ“Š System Requirements & Costs

### Hardware Requirements
- **CPU**: Multi-core processor (4+ cores recommended)
- **RAM**: 8GB minimum, 16GB recommended for large document sets
- **Storage**: 2GB + (3x document size) for vector index
- **Internet**: Required for Gemini API calls

### API Usage & Costs
- **Gemini API**: Free tier available (60 requests/minute)
  - Embedding: Included in generation quota
  - Generation: ~1M tokens/month free
- **Pricing**: See [Google AI Pricing](https://ai.google.dev/pricing)

### Performance Benchmarks
| Document Size | Index Build Time | Query Time | Memory Usage |
|---------------|------------------|------------|--------------|
| 10 files (50MB) | ~30 seconds | ~2 seconds | ~500MB |
| 50 files (200MB) | ~2 minutes | ~3 seconds | ~1.5GB |
| 100 files (500MB) | ~5 minutes | ~4 seconds | ~3GB |

*Note: Times vary based on file formats and internet speed*

---

## ğŸ“ Development History & Evolution

### Version Evolution

#### v1.0 - Initial Custom Implementation
- Manual PDF/TXT loading with PyPDF2
- SentenceTransformer local embeddings
- In-memory FAISS index (no persistence)
- Basic Streamlit UI

#### v2.0 - LangChain Migration
- Switched to LangChain document loaders
- OpenAI embeddings (later reverted to Gemini)
- Chroma vector store with persistence
- RetrievalQA chain orchestration
- Enhanced error handling

#### v3.0 - Multimodal Enhancement
- Added image support (Gemini Vision API)
- Added video processing capabilities
- Excel and PowerPoint support
- Improved chunking strategy
- Better metadata handling

#### v4.0 - Current Version (Clean Corporate UI)
- Complete UI refactor to Clean Corporate design
- Separated UI styles into `ui_styles.py`
- High-contrast accessibility improvements
- Dual-mode operation (RAG/Gemini-Only)
- Word document support (.docx/.doc)
- Enhanced chunk display with HTML escaping
- Removed unused code and dependencies
- Production-ready error handling

### Key Architectural Decisions

**Why LangChain?**
- Industry-standard RAG framework
- Better code maintainability
- Built-in error handling
- Active community support
- Easy to extend and customize

**Why FAISS over Chroma?**
- Faster similarity search
- Lower memory footprint
- No external database dependency
- Simpler deployment
- Better for CPU-only environments

**Why Gemini over OpenAI?**
- Multimodal capabilities (images/video)
- Generous free tier
- Lower latency in most regions
- Native integration with Google ecosystem
- Cost-effective for production

### Code Quality Improvements
- Reduced boilerplate by ~60%
- Modular architecture (UI separated from logic)
- Comprehensive error handling
- Detailed logging and status messages
- Type hints and documentation
- Git version control

---

## ğŸš§ Known Limitations & Future Enhancements

### Current Limitations
- **Single-user**: No authentication or multi-user support
- **No streaming**: Responses appear all at once (no progressive display)
- **Limited file upload**: Must manually add files to `data/` folder
- **No conversation memory**: Each query is independent (session-based only)
- **CPU-only FAISS**: GPU acceleration not utilized
- **No OCR for scanned PDFs**: Text must be extractable

### Planned Enhancements
- [ ] **User Authentication**: Add login system for multi-user deployment
- [ ] **Streaming Responses**: Progressive answer display with `st.write_stream()`
- [ ] **File Upload UI**: Drag-and-drop interface for document upload
- [ ] **Conversation History**: Persistent chat memory across sessions
- [ ] **Advanced Analytics**: Dashboard for usage statistics and insights
- [ ] **Multi-language Support**: Internationalization (i18n)
- [ ] **Export Features**: Download chat history, save reports
- [ ] **Advanced Filters**: Filter by document type, date, author
- [ ] **Feedback Loop**: User ratings to improve retrieval quality
- [ ] **API Endpoint**: REST API for programmatic access
- [ ] **Docker Deployment**: Containerized deployment option
- [ ] **Cloud Integration**: Support for cloud storage (S3, Google Drive)

---

## ğŸ“– Additional Resources

### Documentation
- **LangChain Docs**: [python.langchain.com](https://python.langchain.com)
- **Gemini API**: [ai.google.dev/docs](https://ai.google.dev/docs)
- **Streamlit Docs**: [docs.streamlit.io](https://docs.streamlit.io)
- **FAISS Docs**: [github.com/facebookresearch/faiss](https://github.com/facebookresearch/faiss)

### Tutorials & Guides
- [Building RAG Applications](https://python.langchain.com/docs/tutorials/rag/)
- [Gemini Multimodal Guide](https://ai.google.dev/gemini-api/docs/vision)
- [Streamlit App Development](https://docs.streamlit.io/develop/tutorials)

### Community & Support
- **Issues**: Report bugs on GitHub
- **Discussions**: Join LangChain Discord
- **Updates**: Follow Google AI blog

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. **Report Bugs**: Open an issue with reproduction steps
2. **Suggest Features**: Describe use cases and benefits
3. **Submit PRs**: Fork, create branch, make changes, submit PR
4. **Improve Docs**: Fix typos, add examples, clarify instructions
5. **Share Use Cases**: Let us know how you're using the system

### Development Setup
```powershell
# Clone repository
git clone <repo-url>
cd rag_system

# Create dev environment
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt

# Make changes
# Test thoroughly
# Commit with descriptive messages
# Push and create PR
```

---

## ğŸ“œ License

This project is open source and available under the **MIT License**.

```
MIT License

Copyright (c) 2026 Document AI Assistant Contributors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ğŸ™ Acknowledgments

### Technologies
- **Google Gemini AI** - Multimodal language model and embeddings
- **LangChain** - RAG framework and orchestration
- **Streamlit** - Web application framework
- **FAISS** - Vector similarity search (Facebook Research)
- **PyPDF2, Pillow, pandas, openpyxl, python-pptx, docx2txt** - Document processing

### Inspiration
- OpenAI's GPT documentation and RAG examples
- LangChain community tutorials and use cases
- Streamlit gallery projects

### Contributors
- Community feedback and bug reports
- Open source library maintainers
- Documentation improvements

---

## ğŸ“ Contact & Support

- **Documentation**: This README
- **Issues**: GitHub Issues tab
- **Email**: [your-email@example.com]
- **Updates**: Check GitHub for latest releases

---

**Built with â¤ï¸ using LangChain, Google Gemini, and Streamlit**

*Last Updated: January 2026*

1. **Clone and navigate to the project**:
```powershell
cd rag_system
```

2. **Create and activate virtual environment**:
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

3. **Install dependencies**:
```powershell
pip install --upgrade pip
pip install -r requirements.txt
```

4. **Set your Gemini API key**:
```powershell
$env:GEMINI_API_KEY='your-api-key-here'
```

5. **Place your documents** in the `data/` folder

6. **Run the application**:
```powershell
streamlit run app.py
```

Or use the helper script:
```powershell
.\run_app.ps1
```

## ğŸ“ Supported File Types

| Type | Extensions | Description |
|------|------------|-------------|
| ğŸ“„ PDF | `.pdf` | Extracts text from PDF documents |
| ğŸ“Š Spreadsheets | `.csv`, `.xlsx`, `.xls` | Processes tabular data |
| ğŸ“‘ Presentations | `.pptx`, `.ppt` | Extracts content from slides |
| ğŸ“ Text | `.txt` | Plain text files |
| ğŸ–¼ï¸ Images | `.jpg`, `.jpeg`, `.png` | OCR and image description |

## ğŸ”§ Configuration

### Chunking Parameters
- **Chunk Size**: 1000 characters
- **Chunk Overlap**: 200 characters
- **Retrieval**: Top 5 most similar chunks

### Models Used
- **Generation**: `gemini-2.0-flash-exp`
- **Embeddings**: `text-embedding-004`
- **Vector Store**: FAISS (CPU)

## ğŸ“¦ Project Structure

```
rag_system/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ run_app.ps1                # PowerShell launcher script
â”œâ”€â”€ data/                      # Place your documents here
â”œâ”€â”€ .cache/                    # Hugging Face cache
â”œâ”€â”€ .faiss_index/              # Vector store index
â””â”€â”€ scripts/                   # Setup helper scripts
```

## ğŸ› ï¸ Troubleshooting

### Common Issues

**NumPy Build Errors**:
```powershell
pip install numpy==1.26.4 --prefer-binary
```

**FAISS Installation Issues**:
Use conda instead:
```powershell
conda install -c conda-forge faiss-cpu
```

**API Key Not Set**:
Make sure to set the environment variable before running:
```powershell
$env:GEMINI_API_KEY='your-key'
```

### Using Conda (Alternative)

```powershell
.\scripts\setup_conda.ps1
# or manually:
conda create -n rag python=3.11 -y
conda activate rag
conda install -c conda-forge faiss-cpu -y
pip install -r requirements.txt
```

## ğŸ¯ Usage Tips

1. **Add Documents**: Place files in the `data/` folder
2. **Re-scan**: Click "ğŸ”„ Re-Scan Folder" in the sidebar after adding files
3. **Ask Questions**: Use the chat interface to query your documents
4. **View Sources**: Expand the retrieved context to see source chunks
5. **Compare**: Use the RAG comparison demo to see the difference

## ğŸ§ª RAG vs No-RAG Comparison

The app includes a demo section showing:
- **Without RAG**: Model answers from general knowledge only
- **With RAG**: Model answers using your specific documents

This demonstrates the power of retrieval-augmented generation!

## ğŸ“„ License

This project is open source and available under the MIT License.

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome!

## ğŸ™ Acknowledgments

- Google Gemini AI
- LangChain
- Streamlit
- FAISS by Facebook Research
